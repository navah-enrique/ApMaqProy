{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Survival Model to MLflow\n",
    "\n",
    "@roman_avj\n",
    "\n",
    "7 nov 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravj/opt/anaconda3/envs/dd3surv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/ravj/opt/anaconda3/envs/dd3surv/lib/python3.9/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import sqlalchemy\n",
    "import mlflow\n",
    "import cloudpickle\n",
    "\n",
    "\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgbse import XGBSEStackedWeibull\n",
    "from xgbse.extrapolation import extrapolate_constant_risk\n",
    "import lifelines\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "from xgbse.metrics import (\n",
    "    approx_brier_score,\n",
    "    dist_calibration_score,\n",
    "    concordance_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26541 entries, 0 to 26540\n",
      "Columns: 141 entries, id to cosine_tmonth\n",
      "dtypes: datetime64[us](2), float64(122), int32(1), int64(4), object(9), string(3)\n",
      "memory usage: 28.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# read\n",
    "df_model = pd.read_parquet('../../data/data2analyze_clean_v2_rent.parquet')\n",
    "df_model.info()\n",
    "\n",
    "# add if has maintenance\n",
    "df_model['has_maintenance'] = df_model['cost_of_maintenance'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# clip columns with 'lag' up to 99 percentile\n",
    "vars_lag = df_model.columns[df_model.columns.str.contains('lag')]\n",
    "df_model[vars_lag] = df_model[vars_lag].clip(upper=df_model[vars_lag].quantile(0.99), axis=1)\n",
    "\n",
    "# look rows with maximum time2event\n",
    "df_max = df_model[df_model['time2event'] == df_model['time2event'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26541 entries, 0 to 26540\n",
      "Data columns (total 22 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   listing_type                       26541 non-null  category\n",
      " 1   property_type                      26541 non-null  category\n",
      " 2   first_price                        26541 non-null  float64 \n",
      " 3   diff_first_prediction              26541 non-null  float64 \n",
      " 4   prediction_price_per_square_meter  26541 non-null  float64 \n",
      " 5   surface_total                      26541 non-null  float64 \n",
      " 6   page_on_marketplace                26541 non-null  float64 \n",
      " 7   is_new_property_prob               26541 non-null  float64 \n",
      " 8   total_cost_of_living               26541 non-null  float64 \n",
      " 9   green_index                        26541 non-null  float64 \n",
      " 10  days_active                        26541 non-null  float64 \n",
      " 11  relative_cost_of_living            26541 non-null  float64 \n",
      " 12  pets_allowed                       26541 non-null  int8    \n",
      " 13  num_bathrooms                      26541 non-null  float64 \n",
      " 14  num_parking_lots                   26541 non-null  float64 \n",
      " 15  latitude                           26541 non-null  float64 \n",
      " 16  longitude                          26541 non-null  float64 \n",
      " 17  sine_tmonth                        26541 non-null  float64 \n",
      " 18  cosine_tmonth                      26541 non-null  float64 \n",
      " 19  woe_marketplace                    26541 non-null  float64 \n",
      " 20  woe_seller                         26541 non-null  float64 \n",
      " 21  woe_id_sepomex                     26541 non-null  float64 \n",
      "dtypes: category(2), float64(19), int8(1)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "# select columns\n",
    "vars_x_categorical = ['listing_type', 'property_type']\n",
    "vars_x_discrete = ['num_bathrooms', 'num_parking_lots']\n",
    "vars_x_woe = ['woe_marketplace', 'woe_seller', 'woe_id_sepomex']\n",
    "vars_x_numerical = [\n",
    "    'first_price', 'diff_first_prediction', \n",
    "    'prediction_price_per_square_meter',\n",
    "    'surface_total', 'page_on_marketplace',\n",
    "    'is_new_property_prob', 'total_cost_of_living', 'green_index', 'days_active',\n",
    "    'relative_cost_of_living'\n",
    "    ]\n",
    "vars_x_binary = ['pets_allowed']\n",
    "vars_x_geographic = ['latitude', 'longitude']\n",
    "vars_x_time = ['sine_tmonth', 'cosine_tmonth']\n",
    "\n",
    "vars_x_names = vars_x_categorical + vars_x_numerical + vars_x_binary + vars_x_discrete + vars_x_geographic + vars_x_time + vars_x_woe\n",
    "\n",
    "# corroborate there are not duplicates in the vars_x_names\n",
    "print(len(vars_x_names))\n",
    "print(len(set(vars_x_names)))\n",
    "\n",
    "# get y data as sksurv need\n",
    "data_y = np.array(\n",
    "    list(zip(df_model['event'], df_model['time2event'])),\n",
    "    dtype=[('Status', '?'), ('Survival_in_days', '<f8')]\n",
    ")\n",
    "\n",
    "# get x data\n",
    "data_x = (\n",
    "    df_model.copy()\n",
    "    .astype({col: 'category' for col in vars_x_categorical})\n",
    "    .astype({col: np.float64 for col in vars_x_numerical + vars_x_discrete + vars_x_binary + vars_x_geographic + vars_x_woe + vars_x_time})\n",
    "    .astype({col: np.int8 for col in vars_x_binary})\n",
    "    [vars_x_names]\n",
    ")\n",
    "data_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dropped categorical variable 'listing_type', because it has only 1 values\n"
     ]
    }
   ],
   "source": [
    "def boxcox(X):\n",
    "    # power_transform\n",
    "    power_transform = PowerTransformer(method='yeo-johnson', standardize=True).fit(X)\n",
    "    X_transf = power_transform.transform(X)\n",
    "    return X_transf, power_transform\n",
    "\n",
    "def scale(X):\n",
    "    # power_transform\n",
    "    standard_scaler = StandardScaler().fit(X)\n",
    "    X_transf = standard_scaler.transform(X)\n",
    "    return X_transf, standard_scaler\n",
    "\n",
    "# one hot encoding #\n",
    "data_x_numeric = OneHotEncoder().fit_transform(data_x)\n",
    "colnames_x_numeric = data_x_numeric.columns\n",
    "\n",
    "# get boxcox transformation for each property type\n",
    "boxcox_vars_property = [\n",
    "    'first_price', 'prediction_price_per_square_meter', 'surface_total', 'is_new_property_prob'\n",
    "]\n",
    "# difference between vars_x_numerical and boxcox_vars_property\n",
    "boxcox_vars_all = list(set(vars_x_numerical) - set(boxcox_vars_property))\n",
    "# box cox transformation by property type #\n",
    "# subset data\n",
    "idx_house = (data_x_numeric['property_type=house'] >= 1)\n",
    "idx_apartment = (data_x_numeric['property_type=house'] < 1)\n",
    "\n",
    "# get boxcox transformation\n",
    "data_x_numeric.loc[idx_house, boxcox_vars_property], pt_house = boxcox(data_x_numeric.loc[idx_house, boxcox_vars_property])\n",
    "data_x_numeric.loc[idx_apartment, boxcox_vars_property], pt_apartment = boxcox(data_x_numeric.loc[idx_apartment, boxcox_vars_property])\n",
    "data_x_numeric[boxcox_vars_all], pt_all = boxcox(data_x_numeric[boxcox_vars_all])\n",
    "\n",
    "# scale #\n",
    "# get scaler transformation for each property type\n",
    "standard_vars = vars_x_discrete\n",
    "# scaler transformation by property type #\n",
    "# subset data\n",
    "idx_house = (data_x_numeric['property_type=house'] >= 1)\n",
    "idx_apartment = (data_x_numeric['property_type=house'] < 1)\n",
    "\n",
    "# get scaler transformation\n",
    "data_x_numeric.loc[idx_house, standard_vars], st_house = scale(data_x_numeric.loc[idx_house, standard_vars])\n",
    "data_x_numeric.loc[idx_apartment, standard_vars], st_apartment = scale(data_x_numeric.loc[idx_apartment, standard_vars])\n",
    "# to numeric\n",
    "data_x_numeric = data_x_numeric.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_type=house', 'first_price', 'diff_first_prediction',\n",
       "       'prediction_price_per_square_meter', 'surface_total',\n",
       "       'page_on_marketplace', 'is_new_property_prob', 'total_cost_of_living',\n",
       "       'green_index', 'days_active', 'relative_cost_of_living', 'pets_allowed',\n",
       "       'num_bathrooms', 'num_parking_lots', 'latitude', 'longitude',\n",
       "       'sine_tmonth', 'cosine_tmonth', 'woe_marketplace', 'woe_seller',\n",
       "       'woe_id_sepomex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames_x_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_x_numeric, data_y, test_size=0.1, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23886, 21)\n",
      "(2655, 21)\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hyperparams\n",
    "import json\n",
    "with open('best_params.json', 'r') as f:\n",
    "    hyperparams = json.load(f)\n",
    "\n",
    "# set hyperparams\n",
    "hyperparams['monotone_constraints'] = tuple(hyperparams['monotone_constraints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'survival:aft',\n",
       " 'eval_metric': 'aft-nloglik',\n",
       " 'aft_loss_distribution': 'normal',\n",
       " 'aft_loss_distribution_scale': 1,\n",
       " 'tree_method': 'hist',\n",
       " 'learning_rate': 0.0661009829541915,\n",
       " 'max_depth': 15,\n",
       " 'booster': 'dart',\n",
       " 'subsample': 0.5,\n",
       " 'min_child_weight': 50,\n",
       " 'colsample_bynode': 0.5,\n",
       " 'reg_alpha': 0.9328679988478339,\n",
       " 'reg_lambda': 0.3157995934870487,\n",
       " 'monotone_constraints': (0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-aft-nloglik:11.32935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalidation-aft-nloglik:3.56287\n",
      "[100]\tvalidation-aft-nloglik:3.54653\n",
      "[134]\tvalidation-aft-nloglik:3.54966\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={&#x27;aft_loss_distribution&#x27;: &#x27;normal&#x27;,\n",
       "                                &#x27;aft_loss_distribution_scale&#x27;: 1,\n",
       "                                &#x27;booster&#x27;: &#x27;dart&#x27;, &#x27;colsample_bynode&#x27;: 0.5,\n",
       "                                &#x27;eval_metric&#x27;: &#x27;aft-nloglik&#x27;,\n",
       "                                &#x27;learning_rate&#x27;: 0.0661009829541915,\n",
       "                                &#x27;max_depth&#x27;: 15, &#x27;min_child_weight&#x27;: 50,\n",
       "                                &#x27;monotone_constraints&#x27;: (0, 1, 1, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0),\n",
       "                                &#x27;objective&#x27;: &#x27;survival:aft&#x27;,\n",
       "                                &#x27;reg_alpha&#x27;: 0.9328679988478339,\n",
       "                                &#x27;reg_lambda&#x27;: 0.3157995934870487,\n",
       "                                &#x27;subsample&#x27;: 0.5, &#x27;tree_method&#x27;: &#x27;hist&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBSEStackedWeibull</label><div class=\"sk-toggleable__content\"><pre>XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={&#x27;aft_loss_distribution&#x27;: &#x27;normal&#x27;,\n",
       "                                &#x27;aft_loss_distribution_scale&#x27;: 1,\n",
       "                                &#x27;booster&#x27;: &#x27;dart&#x27;, &#x27;colsample_bynode&#x27;: 0.5,\n",
       "                                &#x27;eval_metric&#x27;: &#x27;aft-nloglik&#x27;,\n",
       "                                &#x27;learning_rate&#x27;: 0.0661009829541915,\n",
       "                                &#x27;max_depth&#x27;: 15, &#x27;min_child_weight&#x27;: 50,\n",
       "                                &#x27;monotone_constraints&#x27;: (0, 1, 1, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0),\n",
       "                                &#x27;objective&#x27;: &#x27;survival:aft&#x27;,\n",
       "                                &#x27;reg_alpha&#x27;: 0.9328679988478339,\n",
       "                                &#x27;reg_lambda&#x27;: 0.3157995934870487,\n",
       "                                &#x27;subsample&#x27;: 0.5, &#x27;tree_method&#x27;: &#x27;hist&#x27;})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={'aft_loss_distribution': 'normal',\n",
       "                                'aft_loss_distribution_scale': 1,\n",
       "                                'booster': 'dart', 'colsample_bynode': 0.5,\n",
       "                                'eval_metric': 'aft-nloglik',\n",
       "                                'learning_rate': 0.0661009829541915,\n",
       "                                'max_depth': 15, 'min_child_weight': 50,\n",
       "                                'monotone_constraints': (0, 1, 1, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0),\n",
       "                                'objective': 'survival:aft',\n",
       "                                'reg_alpha': 0.9328679988478339,\n",
       "                                'reg_lambda': 0.3157995934870487,\n",
       "                                'subsample': 0.5, 'tree_method': 'hist'})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit weibull\n",
    "xgbse_weibull = XGBSEStackedWeibull(hyperparams) # use vanilla method, has performed better\n",
    "y_max = y_train['Survival_in_days'].max().astype(int)\n",
    "\n",
    "xgbse_weibull.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=50,\n",
    "    time_bins = range(1, y_max, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>cindex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apartment</th>\n",
       "      <td>26.379030</td>\n",
       "      <td>0.657299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>28.681993</td>\n",
       "      <td>0.664252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rmse    cindex\n",
       "property_type                     \n",
       "apartment      26.379030  0.657299\n",
       "house          28.681993  0.664252"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_xgbse_mean_time(df):\n",
    "    \"\"\"Get mean time to event for a given time interval.\"\"\"\n",
    "    # get linespace from names of columns\n",
    "    delta = df.columns.astype(int).to_numpy()\n",
    "    # get survival probabilities as the values of the dataframe\n",
    "    surv_probas = df.values\n",
    "\n",
    "    # for each row, compute the area under the curve\n",
    "    mean_time = np.array([simpson(y=y, x=delta) for y in surv_probas])\n",
    "\n",
    "    return(mean_time)\n",
    "\n",
    "def get_metrics(df):\n",
    "    df = df.copy()\n",
    "    cindex = concordance_index_censored(df['event'], df['observed_time'], df['risk_score'])[0]\n",
    "    # rmse & mape for all with event as True\n",
    "    rmse = np.sqrt(np.mean((df[df['event']]['predicted_time'] - df[df['event']]['observed_time'])**2))\n",
    "    return pd.Series({'rmse': rmse, 'cindex': cindex})\n",
    "\n",
    "def get_prediction_df(X, y, colnames, model):\n",
    "    # get rmse, mape and cindex by listing & property type\n",
    "    df_pred = (\n",
    "        pd.DataFrame(X, columns=colnames)\n",
    "        .assign(\n",
    "            observed_time=y['Survival_in_days'],\n",
    "            event=y['Status'],\n",
    "            predicted_time=model.predict(X).pipe(get_xgbse_mean_time),\n",
    "            risk_score=lambda x: - x['predicted_time']\n",
    "        )\n",
    "        .rename(columns={\n",
    "        'property_type=house': 'property_type',\n",
    "        })\n",
    "        .assign(\n",
    "            property_type=lambda x: np.where(x['property_type'] == 1, 'house', 'apartment'),\n",
    "        )  \n",
    "    )\n",
    "\n",
    "    return df_pred\n",
    "\n",
    "# get prediction df\n",
    "df_pred = get_prediction_df(X_test, y_test, colnames_x_numeric, xgbse_weibull)\n",
    "\n",
    "# get metrics\n",
    "table_metrics = (\n",
    "    df_pred\n",
    "    .groupby(['property_type'])\n",
    "    .apply(get_metrics)\n",
    ")\n",
    "table_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://dd360-ds-artifacts/134', creation_time=1699546350370, experiment_id='134', last_update_time=1699546350370, lifecycle_stage='active', name='liquidity-cdmx', tags={}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\" # prod\n",
    "\n",
    "# track server\n",
    "TRACKING_SERVER_HOST = \"mlflow.prod.dd360.mx\" # fill in with the public DNS of the EC2 instance\n",
    "\n",
    "# set uri\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:443\")\n",
    "\n",
    "# experiment\n",
    "EXPERIMENT_NAME = \"liquidity-cdmx\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloudpickle\n",
    "pt_all_serialized = cloudpickle.dumps(pt_all)\n",
    "pt_house_serialized = cloudpickle.dumps(pt_house)\n",
    "pt_apartment_serialized = cloudpickle.dumps(pt_apartment)\n",
    "st_apartment_serialized = cloudpickle.dumps(st_apartment)\n",
    "st_house_serialized = cloudpickle.dumps(st_house)\n",
    "xgbse_weibull_serialized = cloudpickle.dumps(xgbse_weibull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/13 09:11:13 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2023/11/13 09:11:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "/Users/ravj/opt/anaconda3/envs/dd3surv/lib/python3.9/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/Users/ravj/opt/anaconda3/envs/dd3surv/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2023/11/13 09:11:18 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2023/11/13 09:11:20 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2023/11/13 09:11:22 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2023/11/13 09:11:24 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "# start run\n",
    "with mlflow.start_run() as run:\n",
    "    # set tags\n",
    "    mlflow.set_tag('model', 'survival')\n",
    "    mlflow.set_tag('model-type', 'xgbse-stacked-weibull')\n",
    "    mlflow.set_tag('model-name', 'liquidity_v1')\n",
    "    mlflow.set_tag('model-version', '1.0.0')\n",
    "    mlflow.set_tag('model-description', 'Modelo de supervivencia para predecir el tiempo de venta de una propiedad')\n",
    "    # log model\n",
    "\n",
    "    # mlflow.log_artifact(xgbse_weibull, 'model')\n",
    "    # log variables\n",
    "    mlflow.log_param('variables', vars_x_names)\n",
    "    mlflow.log_param('categorical_variables', vars_x_categorical)\n",
    "    mlflow.log_param('discrete_variables', vars_x_discrete)\n",
    "    mlflow.log_param('woe_variables', vars_x_woe)\n",
    "    mlflow.log_param('numerical_variables', vars_x_numerical)\n",
    "    mlflow.log_param('binary_variables', vars_x_binary)\n",
    "    mlflow.log_param('geographic_variables', vars_x_geographic)\n",
    "    mlflow.log_param('time_variables', vars_x_time)\n",
    "    # log transformations\n",
    "    mlflow.sklearn.log_model(pt_all_serialized, 'pt_all', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    mlflow.sklearn.log_model(pt_house_serialized, 'pt_house', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    mlflow.sklearn.log_model(pt_apartment_serialized, 'pt_apartment', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    mlflow.sklearn.log_model(st_apartment_serialized, 'st_apartment', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    mlflow.sklearn.log_model(st_house_serialized, 'st_house', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    mlflow.sklearn.log_model(xgbse_weibull_serialized, 'xgbse_weibull', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n",
    "    # log all the table_metrics\n",
    "    for index, row in table_metrics.iterrows():\n",
    "        mlflow.log_metric(f\"rmse_{index[0]}_{index[1]}\", row['rmse'])\n",
    "        mlflow.log_metric(f\"cindex_{index[0]}_{index[1]}\", row['cindex'])\n",
    "    \n",
    "# end run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00,  9.44it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 26.44it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# # get log id\n",
    "# log_id = \"39d3eadaedf5499d9051fdfa94bd6994\"\n",
    "\n",
    "# # load models #\n",
    "# # load power transform\n",
    "# power_transform_load = cloudpickle.loads(mlflow.sklearn.load_model(f\"runs:/{log_id}/power_transform\"))\n",
    "# # load standard scaler\n",
    "# standard_scaler_load = cloudpickle.loads(mlflow.sklearn.load_model(f\"runs:/{log_id}/standard_scaler\"))\n",
    "# # # load xgbse weibull\n",
    "# xgbse_weibull_load =  cloudpickle.loads(mlflow.sklearn.load_model(f\"runs:/{log_id}/xgbse_weibull\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>73938.0</td>\n",
       "      <td>73938.0</td>\n",
       "      <td>73938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            15       16       17\n",
       "count  73938.0  73938.0  73938.0\n",
       "mean       0.0      0.0      0.0\n",
       "std        0.0      0.0      0.0\n",
       "min        0.0      0.0      0.0\n",
       "25%        0.0      0.0      0.0\n",
       "50%        0.0      0.0      0.0\n",
       "75%        0.0      0.0      0.0\n",
       "max        0.0      0.0      0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # look transformed data is the same as original\n",
    "# data_aux = data_x[vars_x_discrete + vars_x_geographic].copy()\n",
    "# (pd.DataFrame(standard_scaler_load.inverse_transform(data_x_numeric_aux_scale), columns=location_cols_scale) - pd.DataFrame(standard_scaler_load.inverse_transform(data_x_numeric_aux_scale), columns=location_cols_scale)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={&#x27;aft_loss_distribution&#x27;: &#x27;normal&#x27;,\n",
       "                                &#x27;aft_loss_distribution_scale&#x27;: 1,\n",
       "                                &#x27;booster&#x27;: &#x27;dart&#x27;, &#x27;colsample_bynode&#x27;: 0.5,\n",
       "                                &#x27;eval_metric&#x27;: &#x27;aft-nloglik&#x27;,\n",
       "                                &#x27;learning_rate&#x27;: 0.05, &#x27;max_depth&#x27;: 8,\n",
       "                                &#x27;min_child_weight&#x27;: 50,\n",
       "                                &#x27;objective&#x27;: &#x27;survival:aft&#x27;, &#x27;subsample&#x27;: 0.5,\n",
       "                                &#x27;tree_method&#x27;: &#x27;hist&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBSEStackedWeibull</label><div class=\"sk-toggleable__content\"><pre>XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={&#x27;aft_loss_distribution&#x27;: &#x27;normal&#x27;,\n",
       "                                &#x27;aft_loss_distribution_scale&#x27;: 1,\n",
       "                                &#x27;booster&#x27;: &#x27;dart&#x27;, &#x27;colsample_bynode&#x27;: 0.5,\n",
       "                                &#x27;eval_metric&#x27;: &#x27;aft-nloglik&#x27;,\n",
       "                                &#x27;learning_rate&#x27;: 0.05, &#x27;max_depth&#x27;: 8,\n",
       "                                &#x27;min_child_weight&#x27;: 50,\n",
       "                                &#x27;objective&#x27;: &#x27;survival:aft&#x27;, &#x27;subsample&#x27;: 0.5,\n",
       "                                &#x27;tree_method&#x27;: &#x27;hist&#x27;})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={'aft_loss_distribution': 'normal',\n",
       "                                'aft_loss_distribution_scale': 1,\n",
       "                                'booster': 'dart', 'colsample_bynode': 0.5,\n",
       "                                'eval_metric': 'aft-nloglik',\n",
       "                                'learning_rate': 0.05, 'max_depth': 8,\n",
       "                                'min_child_weight': 50,\n",
       "                                'objective': 'survival:aft', 'subsample': 0.5,\n",
       "                                'tree_method': 'hist'})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgbse_weibull_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_type                             for-rent\n",
       "property_type                           apartment\n",
       "first_price                                8900.0\n",
       "diff_first_prediction                   -0.097642\n",
       "prediction_price_per_square_meter      142.942667\n",
       "surface_total                                69.0\n",
       "page_on_marketplace                           2.0\n",
       "is_new_property_prob                       0.5044\n",
       "total_cost_of_living                 25043.204753\n",
       "days_active                             24.530747\n",
       "relative_cost_of_living                178.435238\n",
       "is_exterior                                     0\n",
       "has_gym                                         0\n",
       "pets_allowed                                    1\n",
       "has_maintenance                                 0\n",
       "num_bedrooms                                  2.0\n",
       "latitude                                19.478474\n",
       "longitude                              -99.210293\n",
       "woe_marketplace                          0.290533\n",
       "woe_seller                               0.068438\n",
       "woe_id_sepomex                           0.931353\n",
       "sine_tmonth                                   0.0\n",
       "cosine_tmonth                                -1.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one value\n",
    "data_x.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 11.96it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 19.71it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# def load_models(log_id):\n",
    "#     \"\"\"\n",
    "#     Load models from mlflow\n",
    "#     \"\"\"\n",
    "#     # get the model\n",
    "\n",
    "#     # load power transform\n",
    "#     power_transform_load = cloudpickle.loads(mlflow.sklearn.load_model(f\"runs:/{log_id}/power_transform\"))\n",
    "#     # load standard scaler\n",
    "#     standard_scaler_load = cloudpickle.loads(mlflow.sklearn.load_model(f\"runs:/{log_id}/standard_scaler\"))\n",
    "#     # # load xgbse weibull\n",
    "#     xgbse_weibull_load =  cloudpickle.loads(mlflow.sklearn.load_model(f\"runs:/{log_id}/xgbse_weibull\"))\n",
    "\n",
    "#     # save them into a dictionary\n",
    "#     models = {\n",
    "#         \"power_transform\": power_transform_load,\n",
    "#         \"standard_scaler\": standard_scaler_load,\n",
    "#         \"xgbse_weibull\": xgbse_weibull_load\n",
    "#     }\n",
    "#     return models\n",
    "\n",
    "# LOG_ID = \"39d3eadaedf5499d9051fdfa94bd6994\"\n",
    "# models = load_models(LOG_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to cloudpickle\n",
    "with open('models/pt_all.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(pt_all, f)\n",
    "\n",
    "with open('models/pt_house.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(pt_house, f)\n",
    "\n",
    "with open('models/pt_apartment.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(pt_apartment, f)\n",
    "\n",
    "with open('models/st_apartment.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(st_apartment, f)\n",
    "\n",
    "with open('models/st_house.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(st_house, f)\n",
    "\n",
    "with open('models/xgbse_weibull.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(xgbse_weibull, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={&#x27;aft_loss_distribution&#x27;: &#x27;normal&#x27;,\n",
       "                                &#x27;aft_loss_distribution_scale&#x27;: 1,\n",
       "                                &#x27;booster&#x27;: &#x27;dart&#x27;, &#x27;colsample_bynode&#x27;: 0.5,\n",
       "                                &#x27;eval_metric&#x27;: &#x27;aft-nloglik&#x27;,\n",
       "                                &#x27;learning_rate&#x27;: 0.0661009829541915,\n",
       "                                &#x27;max_depth&#x27;: 15, &#x27;min_child_weight&#x27;: 50,\n",
       "                                &#x27;monotone_constraints&#x27;: (0, 1, 1, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0),\n",
       "                                &#x27;objective&#x27;: &#x27;survival:aft&#x27;,\n",
       "                                &#x27;reg_alpha&#x27;: 0.9328679988478339,\n",
       "                                &#x27;reg_lambda&#x27;: 0.3157995934870487,\n",
       "                                &#x27;subsample&#x27;: 0.5, &#x27;tree_method&#x27;: &#x27;hist&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBSEStackedWeibull</label><div class=\"sk-toggleable__content\"><pre>XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={&#x27;aft_loss_distribution&#x27;: &#x27;normal&#x27;,\n",
       "                                &#x27;aft_loss_distribution_scale&#x27;: 1,\n",
       "                                &#x27;booster&#x27;: &#x27;dart&#x27;, &#x27;colsample_bynode&#x27;: 0.5,\n",
       "                                &#x27;eval_metric&#x27;: &#x27;aft-nloglik&#x27;,\n",
       "                                &#x27;learning_rate&#x27;: 0.0661009829541915,\n",
       "                                &#x27;max_depth&#x27;: 15, &#x27;min_child_weight&#x27;: 50,\n",
       "                                &#x27;monotone_constraints&#x27;: (0, 1, 1, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0),\n",
       "                                &#x27;objective&#x27;: &#x27;survival:aft&#x27;,\n",
       "                                &#x27;reg_alpha&#x27;: 0.9328679988478339,\n",
       "                                &#x27;reg_lambda&#x27;: 0.3157995934870487,\n",
       "                                &#x27;subsample&#x27;: 0.5, &#x27;tree_method&#x27;: &#x27;hist&#x27;})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBSEStackedWeibull(weibull_params={},\n",
       "                    xgb_params={'aft_loss_distribution': 'normal',\n",
       "                                'aft_loss_distribution_scale': 1,\n",
       "                                'booster': 'dart', 'colsample_bynode': 0.5,\n",
       "                                'eval_metric': 'aft-nloglik',\n",
       "                                'learning_rate': 0.0661009829541915,\n",
       "                                'max_depth': 15, 'min_child_weight': 50,\n",
       "                                'monotone_constraints': (0, 1, 1, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                                         0, 0, 0, 0, 0),\n",
       "                                'objective': 'survival:aft',\n",
       "                                'reg_alpha': 0.9328679988478339,\n",
       "                                'reg_lambda': 0.3157995934870487,\n",
       "                                'subsample': 0.5, 'tree_method': 'hist'})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloudpickle.load(open(\"models/xgbse_weibull.pkl\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd3surv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
